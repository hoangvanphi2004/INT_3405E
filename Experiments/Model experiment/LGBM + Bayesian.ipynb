{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":81933,"databundleVersionId":9643020,"sourceType":"competition"},{"sourceId":7453542,"sourceType":"datasetVersion","datasetId":921302},{"sourceId":48235751,"sourceType":"kernelVersion"}],"dockerImageVersionId":30805,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport polars as pl\nimport pandas as pd\nfrom sklearn.base import clone\nfrom copy import deepcopy\nimport optuna\nfrom scipy.optimize import minimize\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport re\nfrom colorama import Fore, Style\n\nfrom tqdm import tqdm\nfrom IPython.display import clear_output\nfrom concurrent.futures import ThreadPoolExecutor\n\nimport warnings\nwarnings.filterwarnings('ignore')\npd.options.display.max_columns = None\n\nimport lightgbm as lgb\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import VotingRegressor, StackingRegressor\n\nfrom sklearn.model_selection import *\nfrom sklearn.metrics import *\nfrom bayes_opt import BayesianOptimization\n\nn_splits = 5\nSEED = 42","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:16:51.515020Z","iopub.execute_input":"2024-12-13T07:16:51.515848Z","iopub.status.idle":"2024-12-13T07:16:56.179933Z","shell.execute_reply.started":"2024-12-13T07:16:51.515810Z","shell.execute_reply":"2024-12-13T07:16:56.179202Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Loading","metadata":{}},{"cell_type":"markdown","source":"## Load tabular dataset","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\ntest = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\nsample = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:16:56.181616Z","iopub.execute_input":"2024-12-13T07:16:56.182143Z","iopub.status.idle":"2024-12-13T07:16:56.248102Z","shell.execute_reply.started":"2024-12-13T07:16:56.182115Z","shell.execute_reply":"2024-12-13T07:16:56.247474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:16:56.249178Z","iopub.execute_input":"2024-12-13T07:16:56.249528Z","iopub.status.idle":"2024-12-13T07:16:56.405335Z","shell.execute_reply.started":"2024-12-13T07:16:56.249490Z","shell.execute_reply":"2024-12-13T07:16:56.404493Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train['id'].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:16:56.406095Z","iopub.execute_input":"2024-12-13T07:16:56.406311Z","iopub.status.idle":"2024-12-13T07:16:56.412808Z","shell.execute_reply.started":"2024-12-13T07:16:56.406287Z","shell.execute_reply":"2024-12-13T07:16:56.411850Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load timeseries data","metadata":{}},{"cell_type":"markdown","source":"1. **process_file**: This function process file timeseries, extract general information in the file like count, mean, std, min, 25%, 50%, 75% and max of each features and then the features matrix is flattened to a vector to represent the data in the file\n2. **load_time_series** Format and load all timeseries files after processed in a folder.","metadata":{}},{"cell_type":"code","source":"def process_file(filename, dirname):\n    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n    df.drop('step', axis=1, inplace=True)\n    return df.describe().values.reshape(-1), filename.split('=')[1]\n\ndef load_time_series(dirname) -> pd.DataFrame:\n    ids = os.listdir(dirname)\n    \n    with ThreadPoolExecutor() as executor:\n        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n    \n    stats, indexes = zip(*results)\n    \n    df = pd.DataFrame(stats, columns=[f\"Stat_{i}\" for i in range(len(stats[0]))])\n    df['id'] = indexes\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:16:56.414642Z","iopub.execute_input":"2024-12-13T07:16:56.414886Z","iopub.status.idle":"2024-12-13T07:16:56.427464Z","shell.execute_reply.started":"2024-12-13T07:16:56.414861Z","shell.execute_reply":"2024-12-13T07:16:56.426676Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\ntest_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")\ntime_series_cols = train_ts.columns.tolist()\ntime_series_cols.remove(\"id\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:16:56.428644Z","iopub.execute_input":"2024-12-13T07:16:56.428886Z","iopub.status.idle":"2024-12-13T07:18:05.601772Z","shell.execute_reply.started":"2024-12-13T07:16:56.428861Z","shell.execute_reply":"2024-12-13T07:18:05.600787Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"After that, we encode time series data using an autoencoder, This autoencoder encode the timeseries general features to a compact vector that contain most important information about the file.\r\n\n* **AutoEncoder**:define AutoEncoder mode.\n* **perform_autoencoder**: train the AutoEncoder model and then return the encoded featuresures\nures","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom sklearn.preprocessing import StandardScaler\nclass AutoEncoder(nn.Module):\n    def __init__(self, input_dim, encoding_dim):\n        super(AutoEncoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, encoding_dim*3),\n            nn.LeakyReLU(0.2),\n            nn.Linear(encoding_dim*3, encoding_dim*2),\n            nn.LeakyReLU(0.2),\n            nn.Linear(encoding_dim*2, encoding_dim),\n            nn.LeakyReLU(0.2)\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(encoding_dim, input_dim*2),\n            nn.LeakyReLU(0.2),\n            nn.Linear(input_dim*2, input_dim*3),\n            nn.LeakyReLU(0.2),\n            nn.Linear(input_dim*3, input_dim),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:18:05.602891Z","iopub.execute_input":"2024-12-13T07:18:05.603198Z","iopub.status.idle":"2024-12-13T07:18:07.276703Z","shell.execute_reply.started":"2024-12-13T07:18:05.603170Z","shell.execute_reply":"2024-12-13T07:18:07.275760Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def perform_autoencoder(df, encoding_dim=50, epochs=50, batch_size=32):\n    scaler = StandardScaler()\n    df_scaled = scaler.fit_transform(df)\n\n    data_tensor = torch.FloatTensor(df_scaled)\n\n    input_dim = data_tensor.shape[1]\n    autoencoder = AutoEncoder(input_dim, encoding_dim)\n\n    criterion = F.smooth_l1_loss\n    optimizer = optim.Adam(autoencoder.parameters())\n\n    for epoch in range(epochs):\n        for i in range(0, len(data_tensor), batch_size):\n            batch = data_tensor[i : i + batch_size]\n            optimizer.zero_grad()\n            reconstructed = autoencoder(batch)\n            loss = criterion(reconstructed, batch)\n            loss.backward()\n            optimizer.step()\n\n        if (epoch + 1) % 10 == 0:\n            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}]')\n\n    with torch.no_grad():\n        encoded_data = autoencoder.encoder(data_tensor).numpy()\n\n    df_encoded = pd.DataFrame(encoded_data, columns=[f'Enc_{i + 1}' for i in range(encoded_data.shape[1])])\n\n    return df_encoded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:18:07.277794Z","iopub.execute_input":"2024-12-13T07:18:07.278332Z","iopub.status.idle":"2024-12-13T07:18:07.285203Z","shell.execute_reply.started":"2024-12-13T07:18:07.278295Z","shell.execute_reply":"2024-12-13T07:18:07.284343Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = train_ts.drop('id', axis=1)\ndf_test = test_ts.drop('id', axis=1)\n\ntrain_ts_encoded = perform_autoencoder(df_train, encoding_dim=60, epochs=100, batch_size=32)\ntest_ts_encoded = perform_autoencoder(df_test, encoding_dim=60, epochs=100, batch_size=32)\n\ntime_series_cols = train_ts_encoded.columns.tolist()\n\ntrain_ts_encoded[\"id\"] = train_ts[\"id\"]\ntest_ts_encoded[\"id\"] = test_ts[\"id\"]\ntrain_ts = train_ts_encoded\ntest_ts = test_ts_encoded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:18:07.286230Z","iopub.execute_input":"2024-12-13T07:18:07.286481Z","iopub.status.idle":"2024-12-13T07:18:15.850679Z","shell.execute_reply.started":"2024-12-13T07:18:07.286455Z","shell.execute_reply":"2024-12-13T07:18:15.849733Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Time series data is then merged to the tabular data","metadata":{}},{"cell_type":"code","source":"train = pd.merge(train, train_ts, how=\"left\", on='id')\ntest = pd.merge(test, test_ts, how=\"left\", on='id')\n\ntrain = train.drop('id', axis=1)\ntest = test.drop('id', axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:18:15.851798Z","iopub.execute_input":"2024-12-13T07:18:15.852933Z","iopub.status.idle":"2024-12-13T07:18:15.876812Z","shell.execute_reply.started":"2024-12-13T07:18:15.852876Z","shell.execute_reply":"2024-12-13T07:18:15.876110Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:18:15.877776Z","iopub.execute_input":"2024-12-13T07:18:15.878082Z","iopub.status.idle":"2024-12-13T07:18:15.961061Z","shell.execute_reply.started":"2024-12-13T07:18:15.878054Z","shell.execute_reply":"2024-12-13T07:18:15.960109Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Filtering","metadata":{}},{"cell_type":"markdown","source":"Select the columns which is present in test data to train","metadata":{}},{"cell_type":"code","source":"featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n                'CGAS-Season', 'CGAS-CGAS_Score',\n                'Physical-Season', 'Physical-BMI', 'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference', 'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n                'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage', 'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n                'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND', 'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU', 'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR', 'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI', 'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM', 'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num', 'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM', 'BIA-BIA_TBW',\n                'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season', 'PAQ_C-PAQ_C_Total',\n                'SDS-Season', 'SDS-SDS_Total_Raw', 'SDS-SDS_Total_T', \n                'PreInt_EduHx-Season', 'PreInt_EduHx-computerinternet_hoursday',\n                'sii']\n# 58 columns data(no ID) + target sii\n\nfeaturesCols += time_series_cols\n\ntrain = train[featuresCols]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:18:15.962109Z","iopub.execute_input":"2024-12-13T07:18:15.962371Z","iopub.status.idle":"2024-12-13T07:18:15.969554Z","shell.execute_reply.started":"2024-12-13T07:18:15.962345Z","shell.execute_reply":"2024-12-13T07:18:15.968619Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Drop **all sample** have NaN sii values.","metadata":{}},{"cell_type":"code","source":"train = train.dropna(subset='sii')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:18:15.970551Z","iopub.execute_input":"2024-12-13T07:18:15.970855Z","iopub.status.idle":"2024-12-13T07:18:15.984458Z","shell.execute_reply.started":"2024-12-13T07:18:15.970829Z","shell.execute_reply":"2024-12-13T07:18:15.983626Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Fill the missing categorical data with \"Missing\" ","metadata":{}},{"cell_type":"code","source":"cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', 'Fitness_Endurance-Season', \n          'FGC-Season', 'BIA-Season', 'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n\ndef update(df):\n    for c in cat_c: \n        df[c] = df[c].fillna('Missing')\n        df[c] = df[c].astype('category')\n    return df\n        \ntrain = update(train)\ntest = update(test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:18:15.987031Z","iopub.execute_input":"2024-12-13T07:18:15.987278Z","iopub.status.idle":"2024-12-13T07:18:16.020590Z","shell.execute_reply.started":"2024-12-13T07:18:15.987252Z","shell.execute_reply":"2024-12-13T07:18:16.019745Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create a mapping from string to integer to push data to the model (Use one hot encode instead)","metadata":{}},{"cell_type":"code","source":"def create_mapping(column, dataset):\n    unique_values = dataset[column].unique()\n    return {value: idx for idx, value in enumerate(unique_values)}\n\nfor col in cat_c:\n    mapping_train = create_mapping(col, train)\n    mapping_test = create_mapping(col, test)\n    \n    train[col] = train[col].replace(mapping_train).astype(int)\n    test[col] = test[col].replace(mapping_test).astype(int)\n\nprint(f'Train Shape : {train.shape} || Test Shape : {test.shape}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:18:16.021738Z","iopub.execute_input":"2024-12-13T07:18:16.022056Z","iopub.status.idle":"2024-12-13T07:18:16.062802Z","shell.execute_reply.started":"2024-12-13T07:18:16.022028Z","shell.execute_reply":"2024-12-13T07:18:16.061965Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"Some features are combined to create new features, these features may make model learn better representation of the data","metadata":{}},{"cell_type":"code","source":"def feature_engineering(df):\n    season_cols = [col for col in df.columns if 'Season' in col]\n    df = df.drop(season_cols, axis=1) \n\n    #Age\n    df['BMI_Age'] = df['Physical-BMI'] * df['Basic_Demos-Age']\n    df['Internet_Hours_Age'] = df['PreInt_EduHx-computerinternet_hoursday'] * df['Basic_Demos-Age']\n\n    #BMI\n    df['BMI_Internet_Hours'] = df['Physical-BMI'] * df['PreInt_EduHx-computerinternet_hoursday']\n    df['BFP_BMI'] = df['BIA-BIA_Fat'] / df['BIA-BIA_BMI']\n    df['FFMI_BFP'] = df['BIA-BIA_FFMI'] / df['BIA-BIA_Fat']\n    df['FMI_BFP'] = df['BIA-BIA_FMI'] / df['BIA-BIA_Fat']\n    df['LST_TBW'] = df['BIA-BIA_LST'] / df['BIA-BIA_TBW']\n    df['BFP_BMR'] = df['BIA-BIA_Fat'] * df['BIA-BIA_BMR']\n    df['BFP_DEE'] = df['BIA-BIA_Fat'] * df['BIA-BIA_DEE']\n    df['BMR_Weight'] = df['BIA-BIA_BMR'] / df['Physical-Weight']\n    df['DEE_Weight'] = df['BIA-BIA_DEE'] / df['Physical-Weight']\n    df['SMM_Height'] = df['BIA-BIA_SMM'] / df['Physical-Height']\n    df['Muscle_to_Fat'] = df['BIA-BIA_SMM'] / df['BIA-BIA_FMI']\n    df['Hydration_Status'] = df['BIA-BIA_TBW'] / df['Physical-Weight']\n    df['ICW_TBW'] = df['BIA-BIA_ICW'] / df['BIA-BIA_TBW']\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:18:16.063665Z","iopub.execute_input":"2024-12-13T07:18:16.063899Z","iopub.status.idle":"2024-12-13T07:18:16.070531Z","shell.execute_reply.started":"2024-12-13T07:18:16.063875Z","shell.execute_reply":"2024-12-13T07:18:16.069581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = feature_engineering(train)\ntest = feature_engineering(test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:18:16.071448Z","iopub.execute_input":"2024-12-13T07:18:16.071675Z","iopub.status.idle":"2024-12-13T07:18:16.093828Z","shell.execute_reply.started":"2024-12-13T07:18:16.071650Z","shell.execute_reply":"2024-12-13T07:18:16.092933Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:18:16.094855Z","iopub.execute_input":"2024-12-13T07:18:16.095198Z","iopub.status.idle":"2024-12-13T07:18:16.111786Z","shell.execute_reply.started":"2024-12-13T07:18:16.095160Z","shell.execute_reply":"2024-12-13T07:18:16.110972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:18:16.112756Z","iopub.execute_input":"2024-12-13T07:18:16.113015Z","iopub.status.idle":"2024-12-13T07:18:16.189232Z","shell.execute_reply.started":"2024-12-13T07:18:16.112989Z","shell.execute_reply":"2024-12-13T07:18:16.188239Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train['sii'].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:18:16.190217Z","iopub.execute_input":"2024-12-13T07:18:16.190479Z","iopub.status.idle":"2024-12-13T07:18:16.196329Z","shell.execute_reply.started":"2024-12-13T07:18:16.190452Z","shell.execute_reply":"2024-12-13T07:18:16.195450Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training Function","metadata":{}},{"cell_type":"markdown","source":"**quadratic_weighted_kappa**: calculate QWK value","metadata":{}},{"cell_type":"code","source":"def quadratic_weighted_kappa(y_true, y_pred):\n    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:18:16.197220Z","iopub.execute_input":"2024-12-13T07:18:16.197530Z","iopub.status.idle":"2024-12-13T07:18:16.205583Z","shell.execute_reply.started":"2024-12-13T07:18:16.197504Z","shell.execute_reply":"2024-12-13T07:18:16.204717Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**threshold_Rounder**: Turn the sii from PCIAT_Total to categorical ","metadata":{}},{"cell_type":"code","source":"def threshold_Rounder(oof_non_rounded, thresholds):\n    return np.where(oof_non_rounded < thresholds[0], 0,\n                    np.where(oof_non_rounded < thresholds[1], 1,\n                             np.where(oof_non_rounded < thresholds[2], 2, 3)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:18:16.206537Z","iopub.execute_input":"2024-12-13T07:18:16.206782Z","iopub.status.idle":"2024-12-13T07:18:16.216028Z","shell.execute_reply.started":"2024-12-13T07:18:16.206757Z","shell.execute_reply":"2024-12-13T07:18:16.215378Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**evaluate_predictions**: this function evaluate the prediction of the model by first turn integer prediction values to categorical values and then calculate QWK from it and the true labels.","metadata":{}},{"cell_type":"code","source":"def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n    return -quadratic_weighted_kappa(y_true, rounded_p)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:18:16.217053Z","iopub.execute_input":"2024-12-13T07:18:16.217917Z","iopub.status.idle":"2024-12-13T07:18:16.230415Z","shell.execute_reply.started":"2024-12-13T07:18:16.217847Z","shell.execute_reply":"2024-12-13T07:18:16.229531Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**TrainML**: Train the model using K-Fold, The model is regression model, predict a real value represent how bad the patient was. The value may not explicitly different, so we re-define the threshold to make it split more accurate","metadata":{}},{"cell_type":"code","source":"def TrainML(model_class, test_data):\n    \n    X = train.drop(['sii'], axis=1)\n    y = train['sii']\n\n    # Apply K-Fold\n    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True)\n    \n    train_S = []\n    val_S = []\n    \n    oof_non_rounded = np.zeros(len(y), dtype=float) \n    oof_rounded = np.zeros(len(y), dtype=int) \n    test_preds = np.zeros((len(test_data), n_splits))\n\n    for fold, (train_idx, val_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n        # Train model\n        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n        model = clone(model_class)\n        model.fit(X_train, y_train)\n\n        y_train_pred = model.predict(X_train)\n        y_val_pred = model.predict(X_val)\n\n        # Round to integer values\n        oof_non_rounded[val_idx] = y_val_pred\n        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n        oof_rounded[val_idx] = y_val_pred_rounded\n\n        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n\n        train_S.append(train_kappa)\n        val_S.append(val_kappa)\n\n        #Predict with test dataset\n        test_preds[:, fold] = model.predict(test_data)\n        \n        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n        clear_output(wait=True)\n\n    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n    print(f\"Mean Validation QWK ---> {np.mean(val_S):.4f}\")\n\n    # Using optimizer to find the best threshold\n    KappaOPtimizer = minimize(evaluate_predictions,\n                              x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n                              method='Nelder-Mead') # Nelder-Mead | # Powell\n    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n\n    # Use the threshold retrive from the optimizer to predict again to evaluate\n    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n\n    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n\n    # Use the threshold retrive from the optimizer to predict test\n    tpm = test_preds.mean(axis=1)\n    tpTuned = threshold_Rounder(tpm, KappaOPtimizer.x)\n\n    # Create submition\n    submission = pd.DataFrame({\n        'id': sample['id'],\n        'sii': tpTuned\n    })\n\n    return submission, model, tKappa","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:18:16.231442Z","iopub.execute_input":"2024-12-13T07:18:16.231721Z","iopub.status.idle":"2024-12-13T07:18:16.246617Z","shell.execute_reply.started":"2024-12-13T07:18:16.231684Z","shell.execute_reply":"2024-12-13T07:18:16.245889Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create model and train the model","metadata":{}},{"cell_type":"markdown","source":"### Bayesian Optimization using Gaussian Processes","metadata":{}},{"cell_type":"code","source":"def optimize_hyperparameters(learning_rate, max_depth, num_leaves, min_data_in_leaf, feature_fraction, bagging_fraction, bagging_freq, lambda_l1, lambda_l2):\n    params = {\n        'learning_rate': learning_rate,\n        'max_depth': int(max_depth),\n        'num_leaves': int(num_leaves),\n        'min_data_in_leaf': int(min_data_in_leaf),\n        'feature_fraction': feature_fraction,\n        'bagging_fraction': bagging_fraction,\n        'bagging_freq': int(bagging_freq),\n        'lambda_l1': lambda_l1,\n        'lambda_l2': lambda_l2,\n        'random_state': SEED,\n        'verbose': -1,\n        'n_estimators': 200\n    }\n    LGBM_Model = lgb.LGBMRegressor(**params)\n    _, _, test_Kappa = TrainML(LGBM_Model, test)\n    return np.mean(test_Kappa)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:23:40.489282Z","iopub.execute_input":"2024-12-13T07:23:40.489642Z","iopub.status.idle":"2024-12-13T07:23:40.495470Z","shell.execute_reply.started":"2024-12-13T07:23:40.489613Z","shell.execute_reply":"2024-12-13T07:23:40.494632Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pbounds = {\n    'learning_rate': (0.01, 0.1),\n    'max_depth': (3, 15),\n    'num_leaves': (200, 500),\n'min_data_in_leaf': (5, 20),\n    'feature_fraction': (0.6, 1.0),\n    'bagging_fraction': (0.6, 1.0),\n    'bagging_freq': (1, 5),\n    'lambda_l1': (0, 10),\n    'lambda_l2': (0, 10)\n}\n\noptimizer = BayesianOptimization(\n    f=optimize_hyperparameters,\n    pbounds=pbounds,\n)\n\noptimizer.maximize(init_points=5, n_iter=5)\n\n# Train final model with optimized parameters\nbest_params = optimizer.max['params']\nbest_params['max_depth'] = int(best_params['max_depth'])\nbest_params['num_leaves'] = int(best_params['num_leaves'])\nbest_params['min_data_in_leaf'] = int(best_params['min_data_in_leaf'])\nbest_params['bagging_freq'] = int(best_params['bagging_freq'])\n\nfinal_model = lgb.LGBMRegressor(**best_params, n_estimators=200, random_state=SEED)\nSubmission, model, test_Kappa = TrainML(final_model, test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:25:32.213996Z","iopub.execute_input":"2024-12-13T07:25:32.214869Z","iopub.status.idle":"2024-12-13T07:26:28.635739Z","shell.execute_reply.started":"2024-12-13T07:25:32.214831Z","shell.execute_reply":"2024-12-13T07:26:28.634788Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submit model","metadata":{}},{"cell_type":"code","source":"Submission.to_csv('submission.csv', index=False)\nprint(Submission['sii'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T07:23:57.521115Z","iopub.status.idle":"2024-12-13T07:23:57.521396Z","shell.execute_reply.started":"2024-12-13T07:23:57.521252Z","shell.execute_reply":"2024-12-13T07:23:57.521267Z"}},"outputs":[],"execution_count":null}]}